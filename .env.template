# GenAI Research - Environment Configuration Template
# Copy this file to .env and configure with your values

# ============================================================================
# API Keys
# ============================================================================

# OpenAI API Key (for GPT-4, GPT-4o, GPT-3.5-Turbo, o1, o3-mini models)
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# ============================================================================
# LangSmith Tracing (Optional)
# ============================================================================

# Enable LangSmith for debugging and monitoring
LANGCHAIN_API_KEY=
LANGSMITH_TRACING=false
LANGSMITH_PROJECT=

# ============================================================================
# Database Configuration
# ============================================================================

# PostgreSQL database credentials
# NOTE: Default password works out-of-box. Change in production for security.
DATABASE_URL=postgresql://g3nA1-user:m0re-g3nA1-s3cr3t@postgres:5432/rag_memory
DB_USERNAME=g3nA1-user
DB_PASSWORD=m0re-g3nA1-s3cr3t
DB_HOST=postgres
DB_PORT=5432
DB_NAME=rag_memory

# ============================================================================
# Service URLs (Docker Compose Internal)
# ============================================================================

# FastAPI Backend
FASTAPI_URL=http://fastapi:9020

# ChromaDB Vector Store (internal Docker port is 8000, external host port is 8001)
CHROMA_URL=http://chromadb:8000
CHROMA_HOST=chromadb
CHROMA_PORT=8000
CHROMA_PERSIST_DIRECTORY=/chroma/chroma

# Redis Cache
REDIS_URL=redis://redis:6379/0
REDIS_HOST=redis
REDIS_PORT=6379

# ============================================================================
# Ollama Configuration (for local models)
# ============================================================================
# Ollama host URL
# For native Ollama on host (recommended): http://host.docker.internal:11434
# For Docker Ollama (if re-enabled): http://ollama:11434
OLLAMA_URL=http://host.docker.internal:11434
LLM_OLLAMA_HOST=http://host.docker.internal:11434

# ============================================================================
# Application Configuration
# ============================================================================

# Timeouts (in seconds)
REQUEST_TIMEOUT=600
LLM_TIMEOUT=300

# Logging
LOG_LEVEL=INFO

# Storage
IMAGES_STORAGE_DIR=./stored_images

# Environment
ENVIRONMENT=production

# ============================================================================
# HuggingFace Configuration
# ============================================================================

HUGGINGFACE_VISION_MODEL=Salesforce/blip-image-captioning-base

# ============================================================================
# Advanced Settings (usually don't need to change)
# ============================================================================

# Disable telemetry
ANONYMIZED_TELEMETRY=False

# Celery Redis Database
CELERY_REDIS_DB=1
